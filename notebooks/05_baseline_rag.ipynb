{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 베이스라인 파이프라인\n",
    "\n",
    "Retrieval-Augmented Generation 전체 파이프라인을 구현하고 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "from getpass import getpass\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# 프로젝트 루트 경로\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src import config\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "print(\"RAG 베이스라인 파이프라인\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Key 및 ChromaDB Manager 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key 설정\n",
    "api_key = config.OPENAI_API_KEY\n",
    "\n",
    "if not api_key:\n",
    "    print(\"OpenAI API Key를 입력하세요:\")\n",
    "    api_key = getpass(\"API Key: \")\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "print(\"✅ API Key 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB Manager 로드\n",
    "try:\n",
    "    %store -r chroma_manager\n",
    "    print(\"✅ ChromaDB Manager 로드 완료\")\n",
    "except:\n",
    "    print(\"⚠️ 저장된 ChromaDB Manager가 없습니다. 새로 생성합니다.\")\n",
    "    from src.vectorstore import ChromaDBManager\n",
    "    chroma_manager = ChromaDBManager(api_key=api_key)\n",
    "    chroma_manager.load_vectorstore()\n",
    "\n",
    "# 컬렉션 정보 확인\n",
    "info = chroma_manager.get_collection_info()\n",
    "print(f\"\\n컬렉션: {info.get('name', 'N/A')}\")\n",
    "print(f\"문서 수: {info.get('count', 0):,}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=config.LLM_MODEL,\n",
    "    temperature=config.TEMPERATURE,\n",
    "    max_tokens=config.MAX_TOKENS,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM 모델: {config.LLM_MODEL}\")\n",
    "print(f\"Temperature: {config.TEMPERATURE}\")\n",
    "print(f\"Max Tokens: {config.MAX_TOKENS}\")\n",
    "print(\"\\n✅ LLM 초기화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 프롬프트\n",
    "system_prompt = \"\"\"당신은 RFP(제안요청서) 분석 전문가입니다.\n",
    "주어진 문서 내용을 바탕으로 사용자의 질문에 정확하고 상세하게 답변해주세요.\n",
    "\n",
    "답변 작성 시 다음 규칙을 따르세요:\n",
    "1. 반드시 제공된 문서의 내용만을 사용하여 답변하세요.\n",
    "2. 문서에 없는 내용은 추측하지 말고 \"문서에 해당 정보가 없습니다\"라고 답변하세요.\n",
    "3. 답변은 명확하고 구체적으로 작성하세요.\n",
    "4. 가능한 경우 문서의 어느 부분에서 정보를 얻었는지 언급하세요.\n",
    "5. 한국어로 답변하세요.\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"\"\"참고 문서:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\")\n",
    "])\n",
    "\n",
    "print(\"✅ 프롬프트 템플릿 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG 파이프라인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(\n",
    "    question: str,\n",
    "    top_k: int = config.TOP_K,\n",
    "    filter: dict = None,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    RAG 파이프라인 실행\n",
    "    \n",
    "    Args:\n",
    "        question: 사용자 질문\n",
    "        top_k: 검색할 문서 수\n",
    "        filter: 메타데이터 필터\n",
    "        verbose: 상세 출력 여부\n",
    "    \n",
    "    Returns:\n",
    "        결과 딕셔너리 (answer, sources, retrieved_docs, response_time)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Retrieval\n",
    "    if verbose:\n",
    "        print(\"[1/3] 문서 검색 중...\")\n",
    "    \n",
    "    retrieved_docs = chroma_manager.similarity_search_with_score(\n",
    "        query=question,\n",
    "        k=top_k,\n",
    "        filter=filter\n",
    "    )\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        return {\n",
    "            'answer': \"관련 문서를 찾을 수 없습니다.\",\n",
    "            'sources': [],\n",
    "            'retrieved_docs': [],\n",
    "            'response_time': time.time() - start_time\n",
    "        }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"   → {len(retrieved_docs)}개 문서 검색 완료\")\n",
    "    \n",
    "    # 2. Context 구성\n",
    "    if verbose:\n",
    "        print(\"[2/3] 컨텍스트 구성 중...\")\n",
    "    \n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[문서 {i+1}] (출처: {doc.metadata.get('file_name', 'Unknown')})\\n{doc.page_content}\"\n",
    "        for i, (doc, score) in enumerate(retrieved_docs)\n",
    "    ])\n",
    "    \n",
    "    # 3. Generation\n",
    "    if verbose:\n",
    "        print(\"[3/3] 답변 생성 중...\")\n",
    "    \n",
    "    messages = prompt_template.format_messages(\n",
    "        context=context,\n",
    "        question=question\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    answer = response.content\n",
    "    \n",
    "    # 출처 정보\n",
    "    sources = list(set([\n",
    "        doc.metadata.get('file_name', 'Unknown')\n",
    "        for doc, score in retrieved_docs\n",
    "    ]))\n",
    "    \n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n✅ 완료 (소요 시간: {response_time:.2f}초)\\n\")\n",
    "    \n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'sources': sources,\n",
    "        'retrieved_docs': retrieved_docs,\n",
    "        'response_time': response_time\n",
    "    }\n",
    "\n",
    "print(\"✅ RAG 파이프라인 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 단일 질문 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 질문\n",
    "test_question = \"국민연금공단이 발주한 이러닝시스템 관련 사업 요구사항을 정리해 줘.\"\n",
    "\n",
    "print(f\"질문: {test_question}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = rag_query(test_question, verbose=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n답변:\\n{result['answer']}\")\n",
    "print(f\"\\n출처: {', '.join(result['sources'])}\")\n",
    "print(f\"소요 시간: {result['response_time']:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 프로젝트 가이드의 예시 질문 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 가이드의 질문 예시\n",
    "guide_questions = [\n",
    "    \"국민연금공단이 발주한 이러닝시스템 관련 사업 요구사항을 정리해 줘.\",\n",
    "    \"콘텐츠 개발 관리 요구 사항에 대해서 더 자세히 알려 줘.\",\n",
    "    \"교육이나 학습 관련해서 다른 기관이 발주한 사업은 없나?\",\n",
    "    \"기초과학연구원 극저온시스템 사업 요구에서 AI 기반 예측에 대한 요구사항이 있나?\",\n",
    "    \"한국 원자력 연구원에서 선량 평가 시스템 고도화 사업을 발주했는데, 이 사업이 왜 추진되는지 목적을 알려 줘.\"\n",
    "]\n",
    "\n",
    "print(\"프로젝트 가이드 예시 질문 테스트\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, question in enumerate(guide_questions, 1):\n",
    "    print(f\"\\n[질문 {i}] {question}\\n\")\n",
    "    \n",
    "    result = rag_query(question, verbose=False)\n",
    "    \n",
    "    print(f\"답변: {result['answer'][:300]}...\")\n",
    "    print(f\"출처: {', '.join(result['sources'][:2])}\")\n",
    "    print(f\"시간: {result['response_time']:.2f}초\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 대화형 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_rag():\n",
    "    \"\"\"\n",
    "    대화형 RAG 인터페이스\n",
    "    'quit' 또는 'exit' 입력 시 종료\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"대화형 RAG 시스템 (종료: 'quit' 또는 'exit')\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\n질문: \")\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', '종료']:\n",
    "            print(\"\\n종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        if not question.strip():\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        result = rag_query(question, verbose=False)\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        print(f\"\\n답변:\\n{result['answer']}\")\n",
    "        print(f\"\\n출처: {', '.join(result['sources'])}\")\n",
    "        print(f\"소요 시간: {result['response_time']:.2f}초\")\n",
    "\n",
    "# 실행하려면 주석 해제\n",
    "# interactive_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 성능 평가 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 질문 세트\n",
    "evaluation_questions = [\n",
    "    \"국민연금공단이 발주한 이러닝시스템 관련 사업 요구사항을 정리해 줘.\",\n",
    "    \"콘텐츠 개발 관리 요구 사항에 대해서 더 자세히 알려 줘.\",\n",
    "    \"교육이나 학습 관련해서 다른 기관이 발주한 사업은 없나?\",\n",
    "    \"기초과학연구원 극저온시스템 사업 요구에서 AI 기반 예측에 대한 요구사항이 있나?\",\n",
    "    \"그럼 모니터링 업무에 대한 요청사항이 있는지 찾아보고 알려 줘.\",\n",
    "    \"한국 원자력 연구원에서 선량 평가 시스템 고도화 사업을 발주했는데, 이 사업이 왜 추진되는지 목적을 알려 줘.\",\n",
    "    \"고려대학교 차세대 포털 시스템 사업이랑 광주과학기술원의 학사 시스템 기능개선 사업을 비교해 줄래?\",\n",
    "    \"고려대학교랑 광주과학기술원 각각 응답 시간에 대한 요구사항이 있나? 문서를 기반으로 정확하게 답변해 줘.\",\n",
    "]\n",
    "\n",
    "print(f\"평가용 질문 세트: {len(evaluation_questions)}개\")\n",
    "\n",
    "# 평가 결과 저장\n",
    "evaluation_results = []\n",
    "\n",
    "for i, question in enumerate(evaluation_questions, 1):\n",
    "    print(f\"\\n[{i}/{len(evaluation_questions)}] 평가 중...\")\n",
    "    result = rag_query(question, verbose=False)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        'question': question,\n",
    "        'answer': result['answer'],\n",
    "        'sources': result['sources'],\n",
    "        'response_time': result['response_time'],\n",
    "        'num_sources': len(result['sources'])\n",
    "    })\n",
    "    \n",
    "    print(f\"   완료 ({result['response_time']:.2f}초)\")\n",
    "\n",
    "print(\"\\n✅ 평가 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 결과 요약\n",
    "import numpy as np\n",
    "\n",
    "response_times = [r['response_time'] for r in evaluation_results]\n",
    "num_sources_list = [r['num_sources'] for r in evaluation_results]\n",
    "\n",
    "print(\"\\n베이스라인 성능 요약\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n평가 질문 수: {len(evaluation_results)}개\")\n",
    "print(f\"\\n응답 시간:\")\n",
    "print(f\"  평균: {np.mean(response_times):.2f}초\")\n",
    "print(f\"  중앙값: {np.median(response_times):.2f}초\")\n",
    "print(f\"  최소: {np.min(response_times):.2f}초\")\n",
    "print(f\"  최대: {np.max(response_times):.2f}초\")\n",
    "print(f\"\\n출처 문서 수:\")\n",
    "print(f\"  평균: {np.mean(num_sources_list):.1f}개\")\n",
    "print(f\"  최소: {np.min(num_sources_list)}개\")\n",
    "print(f\"  최대: {np.max(num_sources_list)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 결과 상세 출력\n",
    "print(\"\\n평가 결과 상세:\\n\")\n",
    "\n",
    "for i, result in enumerate(evaluation_results, 1):\n",
    "    print(f\"[질문 {i}]\")\n",
    "    print(f\"Q: {result['question']}\")\n",
    "    print(f\"A: {result['answer'][:200]}...\")\n",
    "    print(f\"출처: {', '.join(result['sources'])}\")\n",
    "    print(f\"시간: {result['response_time']:.2f}초\")\n",
    "    print(\"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 결과를 JSON으로 저장\n",
    "results_dir = project_root / \"data\" / \"processed\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_file = results_dir / f\"baseline_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'config': {\n",
    "            'chunk_size': config.CHUNK_SIZE,\n",
    "            'chunk_overlap': config.CHUNK_OVERLAP,\n",
    "            'embedding_model': config.EMBEDDING_MODEL,\n",
    "            'llm_model': config.LLM_MODEL,\n",
    "            'temperature': config.TEMPERATURE,\n",
    "            'top_k': config.TOP_K\n",
    "        },\n",
    "        'results': evaluation_results,\n",
    "        'summary': {\n",
    "            'num_questions': len(evaluation_results),\n",
    "            'avg_response_time': float(np.mean(response_times)),\n",
    "            'avg_num_sources': float(np.mean(num_sources_list))\n",
    "        }\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 평가 결과 저장 완료: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 베이스라인 완성 체크리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"베이스라인 RAG 시스템 완성 체크리스트\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "checklist = [\n",
    "    \"✅ 문서 로딩 (PDF + HWP)\",\n",
    "    \"✅ 문서 청킹\",\n",
    "    \"✅ 임베딩 생성\",\n",
    "    \"✅ ChromaDB Vector Store 구축\",\n",
    "    \"✅ Retrieval 기능 구현\",\n",
    "    \"✅ LLM 답변 생성\",\n",
    "    \"✅ RAG 파이프라인 통합\",\n",
    "    \"✅ 성능 평가\",\n",
    "    \"✅ 결과 저장\"\n",
    "]\n",
    "\n",
    "for item in checklist:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"베이스라인 구축 완료!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음 단계\n",
    "\n",
    "### 개선 방향\n",
    "\n",
    "1. **Retrieval 고도화**\n",
    "   - Multi-Query Retrieval\n",
    "   - Re-Ranking\n",
    "   - Hybrid Search (BM25 + Vector)\n",
    "   - 메타데이터 필터링 활용\n",
    "\n",
    "2. **Generation 개선**\n",
    "   - 프롬프트 엔지니어링\n",
    "   - Few-shot Learning\n",
    "   - Chain-of-Thought\n",
    "   - 답변 포맷 구조화\n",
    "\n",
    "3. **대화 히스토리**\n",
    "   - 이전 대화 맥락 유지\n",
    "   - 후속 질문 처리\n",
    "\n",
    "4. **평가 체계**\n",
    "   - Retrieval 평가 (Precision, Recall)\n",
    "   - Generation 평가 (Faithfulness, Relevance)\n",
    "   - End-to-End 평가\n",
    "\n",
    "5. **사용자 인터페이스**\n",
    "   - Streamlit 웹 앱 (선택)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
