import os
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

emb = OpenAIEmbeddings(model="text-embedding-3-small")

def build_vector_store(chunks):
    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    persist_dir = os.path.join(BASE_DIR, "chroma_db")

    vector_store = Chroma(
        collection_name="project_collection",
        embedding_function=emb,
        persist_directory=persist_dir,
    )

    # ê¸°ì¡´ DBì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¡œë”©ë§Œ í•˜ê³  ë„˜ì–´ê°€ê¸°
    if vector_store._collection.count() > 0:
        print("ğŸ“Œ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ê°ì§€ë¨ â€” ìƒˆë¡œ ì¶”ê°€í•˜ì§€ ì•Šê³  ë¡œë“œë§Œ ì§„í–‰")
        return vector_store

    # ìƒˆë¡œìš´ DB ìƒì„±
    print("ğŸ”¨ ë²¡í„°ìŠ¤í† ì–´ ë¹„ì–´ìˆìŒ â†’ ë¬¸ì„œ Embedding ì‹œì‘")

    BATCH_SIZE = 100
    for i in range(0, len(chunks), BATCH_SIZE):
        batch = chunks[i:i+BATCH_SIZE]
        vector_store.add_documents(batch)
        print(f"{i + len(batch)}/{len(chunks)} ì²­í¬ Embedding ì™„ë£Œ")

    print("ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ")
    return vector_store
