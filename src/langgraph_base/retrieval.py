import unicodedata, re
from difflib import SequenceMatcher
from langchain_core.documents import Document

from compare_judge_template import classify_question_with_llm

def format_docs(docs):
    formatted = []
    for d in docs:
        title = d.metadata.get("source", None)
        if title:
            formatted.append(f"ğŸ“„ ì›ë¬¸ ë¬¸ì„œëª…: {title}\n{d.page_content}")
        else:
            formatted.append(d.page_content)
    return "\n\n".join(formatted)

def find_docs_by_question(input_data, vector_store, retriever, top_n=1):
    """rag_chainì€ ì—¬ì „íˆ questionë§Œ ì „ë‹¬. ë‚´ë¶€ì—ì„œ ë¹„êµí˜•ì´ë©´ ìë™ ì²˜ë¦¬"""
    question = input_data["question"] if isinstance(input_data, dict) else input_data
    normalized_q = unicodedata.normalize("NFC", str(question))
    docs = vector_store.get(include=["metadatas", "documents"], limit=99999)

    # ğŸ”¥ 1) GPT-5-nanoë¡œ ì§ˆë¬¸ ìœ í˜• íŒë³„
    parsed = classify_question_with_llm(normalized_q)
    q_type = parsed.get("ì§ˆë¬¸ìœ í˜•", "ë‹¨ì¼")

    # ğŸ”¥ 2) ë¹„êµí˜• ì§ˆë¬¸ì´ë©´ compare list ì‚¬ìš©
    if q_type == "ë¹„êµ":
        sub_questions = parsed.get("ë¹„êµ_ì‚¬ì—…", [])
    else:
        sub_questions = [normalized_q]

    # fallback
    if not sub_questions:
        sub_questions = [normalized_q]

    selected_docs = []
    for sub_q in sub_questions[:2]:  # ë¹„êµí˜•ì€ ìµœëŒ€ 2ê°œë§Œ
        scored = []
        for meta, content in zip(docs["metadatas"], docs["documents"]):
            src = unicodedata.normalize("NFC", str(meta.get("source", ""))).strip()
            if not src:
                continue
            sim = SequenceMatcher(None, sub_q, src).ratio()
            scored.append((sim, src, content, meta))
        if scored:
            scored.sort(reverse=True, key=lambda x: x[0])
            top = scored[0]
            selected_docs.append(top)
            print(f"ğŸ“„ ìë™ì„ íƒëœ ë¬¸ì„œ: {top[1]} (ìœ ì‚¬ë„ {top[0]:.3f})")

    if not selected_docs:
        print("âš ï¸ ë¬¸ì„œ ì—†ìŒ â†’ retriever fallback ì‚¬ìš©")
        return retriever.invoke(question)
    
    # ğŸ”¥ ë³‘í•©ëœ contentì™€ metadataë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
    merged_content = "\n\n--- ë¹„êµ ë¬¸ì„œ êµ¬ë¶„ì„  ---\n\n".join([c for _, _, c, _ in selected_docs])
    merged_meta = {
        "sources": [m for _, _, _, m in selected_docs],
        "source": " / ".join([m.get("source", "ë¯¸ê¸°ì¬") for _, _, _, m in selected_docs]),
        "org": " / ".join([m.get("org", "ë¯¸ìƒ") for _, _, _, m in selected_docs]),
        "category": " / ".join([m.get("category", "ë¯¸ìƒ") for _, _, _, m in selected_docs]),
        "budget": " / ".join([m.get("budget", "ë¯¸ê¸°ì¬") for _, _, _, m in selected_docs]),
        "open_date": " / ".join([m.get("open_date", "ë¯¸ê¸°ì¬") for _, _, _, m in selected_docs]),
        "end_date": " / ".join([m.get("end_date", "ë¯¸ê¸°ì¬") for _, _, _, m in selected_docs])
    }
    
    # Document ê°ì²´ë¡œ ë°˜í™˜!
    return [Document(page_content=merged_content, metadata=merged_meta)]





