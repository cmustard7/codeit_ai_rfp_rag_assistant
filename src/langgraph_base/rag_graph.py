# langgraph_base/rag_graph.py
import rag_logger as rl
import time
import json

from langgraph.graph import StateGraph, END

from metadata import extract_metadata
from prompt_template import prompt
from llm_config import get_llm, log_usage
from langgraph_base.rag_evaluate import node_score
from langgraph_base.adaptive_retreival import node_retrieve
from langgraph_base.rag_state import RAGState

# ============================================
# ê°œì„ ëœ ë…¸ë“œë“¤ - ìƒì„¸ ë¡œê¹… í¬í•¨
# ============================================

def node_extract_metadata(state: RAGState):
    """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ + ë¡œê¹…"""
    extract_start = time.time()
    
    metadata = extract_metadata(state['docs'])
    
    extract_time = time.time() - extract_start
    
    # ë©”íƒ€ë°ì´í„° í†µê³„ ë¡œê¹…
    rl.log_metadata({
        "metadata/extraction_time_sec": extract_time,
        "metadata/context_length": len(metadata.get('context', '')),
        "metadata/num_sources": len(metadata.get('source', '').split(' / ')),
        "metadata/has_budget": bool(metadata.get('budget', 'ë¯¸ê¸°ì¬') != 'ë¯¸ê¸°ì¬'),
        "metadata/has_org": bool(metadata.get('org', 'ë¯¸ìƒ') != 'ë¯¸ìƒ'),
        "metadata/has_dates": bool(metadata.get('open_date', 'ë¯¸ê¸°ì¬') != 'ë¯¸ê¸°ì¬'),
        "metadata/retry_count": state.get('retry', 0)
    })
    
    return {'metadata': metadata}

def node_build_prompt(state: RAGState):
    """í”„ë¡¬í”„íŠ¸ êµ¬ì„± + ë¡œê¹…"""
    prompt_start = time.time()
    
    formatted_prompt = prompt.format(
        context=state['metadata']['context'],
        question=state['question'],
        source=state['metadata']['source'],
        org=state['metadata']['org'],
        category=state['metadata']['category'],
        budget=state['metadata']['budget'],
        open_date=state['metadata']['open_date'],
        end_date=state['metadata']['end_date']
    )
    
    prompt_time = time.time() - prompt_start
    
    # í”„ë¡¬í”„íŠ¸ í†µê³„ ë¡œê¹…
    rl.log_prompt({
        "prompt/build_time_sec": prompt_time,
        "prompt/total_length": len(formatted_prompt),
        "prompt/question_length": len(state['question']),
        "prompt/context_length": len(state['metadata']['context']),
        "prompt/context_ratio": len(state['metadata']['context']) / len(formatted_prompt) if len(formatted_prompt) > 0 else 0,
        "prompt/retry_count": state.get('retry', 0)
    })
    
    return {'prompt': formatted_prompt}

def node_llm(state: RAGState):
    """LLM ìƒì„± + ë¡œê¹…"""
    generation_start = time.time()
    
    llm = get_llm('llm')
    raw = llm.invoke(state['prompt'])
    answer = raw.content if hasattr(raw, "content") else str(raw)
    
    generation_time = time.time() - generation_start
    
    # ìƒì„± í†µê³„ ë¡œê¹…
    log_usage('main', raw)  # í† í° + ë¹„ìš©
    
    rl.log_generation({
        'generation/time_sec': generation_time,
        'generation/answer_length': len(answer),
        'generation/answer_word_count': len(answer.split()),
        'generation/chars_per_sec': len(answer) / generation_time if generation_time > 0 else 0,
        'generation/retry_count': state.get('retry', 0)
    })

    return {'answer': answer}

def route_after_scoring(state: RAGState):
    """ì ìˆ˜ì— ë”°ë¥¸ ë¼ìš°íŒ… + ë¡œê¹…"""
    score = state['score']
    retry = state.get('retry', 0)

    print(f"[DECISION] score={score}, retry={retry}")

    # ë¼ìš°íŒ… ê²°ì • ë¡œê¹…
    if score >= 0.75:
        print(" â†’ GOOD (ì¢…ë£Œ)")
        rl.log_routing({
            "routing/decision": "accept",
            "routing/final_score": score,
            "routing/total_retries": retry
        })
        return 'good'

    if retry >= 5:
        print(" â†’ BAD but retry limit reached (ì¢…ë£Œ)")
        rl.log_routing({
            "routing/decision": "forced_accept",
            "routing/final_score": score,
            "routing/total_retries": retry,
            "routing/max_retries_reached": True
        })
        return 'good'

    print(" â†’ BAD (ì¬ê²€ìƒ‰)")
    rl.log_routing({
        "routing/decision": "retry",
        "routing/current_score": score,
        "routing/retry_number": retry + 1
    })
    return 'bad'

def build_graph():
    graph = StateGraph(RAGState)

    graph.add_node('retrieve_docs', node_retrieve)
    graph.add_node('extract_meta', node_extract_metadata)
    graph.add_node('build_prompt', node_build_prompt)
    graph.add_node('generate', node_llm)
    graph.add_node('score', node_score)

    graph.set_entry_point('retrieve_docs')

    graph.add_edge('retrieve_docs', 'extract_meta')
    graph.add_edge('extract_meta', 'build_prompt')
    graph.add_edge('build_prompt', 'generate')
    graph.add_edge('generate', 'score')

    graph.add_conditional_edges(
        'score',
        route_after_scoring,
        {
            'good': END,
            'bad': 'retrieve_docs'
        }
    )

    return graph.compile()

def run_rag_graph(question, vector_store, retriever):
    """Langgraph RAG ì‹¤í–‰ + ì¢…í•© ë¡œê¹…"""
    print(f'ì…ë ¥ ì§ˆë¬¸: {question}')
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘
    pipeline_start = time.time()

    app = build_graph()
    
    try:
        result = app.invoke({
            "question": question,
            "vector_store": vector_store,
            "retriever": retriever,
            "retry": 0
        })
        
        pipeline_duration = time.time() - pipeline_start
        
        # ğŸ”¥ ìµœì¢… íŒŒì´í”„ë¼ì¸ í†µê³„
        rl.log_pipeline({
            'pipeline/total_time_sec': pipeline_duration,
            'pipeline/question': question,
            'pipeline/answer_preview': result["answer"][:100] + "..." if len(result["answer"]) > 100 else result["answer"],
            'pipeline/final_retry_count': result.get('retry', 0),
            'pipeline/final_score': result.get('score', 0.0),
            'pipeline/success': True
        })
        
        print(f'Duration Time: {pipeline_duration:.2f}s')
        
        return result["answer"]
        
    except Exception as e:
        pipeline_duration = time.time() - pipeline_start
        
        rl.log_pipeline({
            'pipeline/total_time_sec': pipeline_duration,
            'pipeline/success': False,
            'pipeline/error': str(e)
        })
        
        print(f'âŒ ì˜¤ë¥˜ ë°œìƒ: {e}')
        raise